{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"FaceDrive: Hands-Free Vehicle Control Using Facial Gestures in CARLA\"\n",
    "This project implements a real-time facial gesture control system for driving in the CARLA simulator. Using MediaPipe, it detects head tilts, mouth movements, and nods to control steering, acceleration, braking, and gear shiftingâ€”enabling intuitive, hands-free vehicle interaction with potential use in assistive driving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.9.21)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import carla\n",
    "from carla import ColorConverter as cc\n",
    "\n",
    "import datetime\n",
    "import logging\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "import weakref\n",
    "import os\n",
    "import sys\n",
    "import pygame\n",
    "\n",
    "try:\n",
    "    import pygame\n",
    "    from pygame.locals import KMOD_CTRL\n",
    "    from pygame.locals import K_BACKSPACE\n",
    "    from pygame.locals import K_COMMA\n",
    "    from pygame.locals import K_DOWN\n",
    "    from pygame.locals import K_ESCAPE\n",
    "    from pygame.locals import K_LEFT\n",
    "    from pygame.locals import K_PERIOD\n",
    "    from pygame.locals import K_RIGHT\n",
    "    from pygame.locals import K_SPACE\n",
    "    from pygame.locals import K_UP\n",
    "    from pygame.locals import K_a\n",
    "    from pygame.locals import K_d\n",
    "    from pygame.locals import K_m\n",
    "    from pygame.locals import K_q\n",
    "    from pygame.locals import K_s\n",
    "    from pygame.locals import K_w\n",
    "    from pygame.locals import K_f\n",
    "except ImportError:\n",
    "    raise RuntimeError('cannot import pygame, make sure pygame package is installed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gesture detection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `FaseGestureDetector` class analyzes facial gesture and features using Mediapipe landmarks. \n",
    "It provides methods to extract 2D coordinates of ears, nose, and lips, and determines head direction \n",
    "(`left`, `right`, `center`, or `undifined`) and lips position ( either mouth is open or close, or `undifined`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaseGestureDetector():\n",
    "    def __init__(self, head_dir_fact=0.5, lips_pos_fact = 1, frown_fact=1):\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        self.mp_holistic = mp.solutions.holistic\n",
    "        self.holistic = self.mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "        self.draw_fasemesh_landmarks = False\n",
    "        self.draw_pose_landmarks = True\n",
    "        self.head_dir_fact = head_dir_fact  # determines the head direction detection sensitivity. (0< and >1) \n",
    "        self.lips_pos_fact = lips_pos_fact  # determins the lips position detection sensitivity. (<0 )\n",
    "        self.frown_fact = frown_fact  # determines the frowning detection sensitivity. (0<)\n",
    "    \n",
    "    def eye(self, facemesh_landmarks, image_shape):\n",
    "        \"\"\" Returns 2D coordinates of left and right eyes based on the facemesh landmarks estimated by mediapipe\"\"\"\n",
    "        if facemesh_landmarks:\n",
    "            landmarks = facemesh_landmarks.landmark\n",
    "            left_eye_2d = np.array([landmarks[159].x * image_shape[1],\n",
    "                                landmarks[159].y * image_shape[0]], dtype=int)      # Index 33 in the facemesh landmarks belongs to the left eye\n",
    "            right_eye_2d = np.array([landmarks[386].x * image_shape[1],\n",
    "                                landmarks[386].y * image_shape[0]], dtype=int)     # Index 263 in the facemesh landmarks belongs to the right eye\n",
    "            return left_eye_2d, right_eye_2d\n",
    "        return None, None\n",
    "    \n",
    "    def eye_brows(self, facemesh_landmarks, image_shape):\n",
    "        \"\"\" Returns 2D coordinates of left and right eyebrows based on the facemesh landmarks estimated by mediapipe\"\"\"\n",
    "        if facemesh_landmarks:\n",
    "            landmarks = facemesh_landmarks.landmark\n",
    "            left_eyebrow_2d = np.array([landmarks[107].x * image_shape[1],\n",
    "                                landmarks[107].y * image_shape[0]], dtype=int)      # Index 107 in the facemesh landmarks belongs to the left eyebrow\n",
    "            right_eyebrow_2d = np.array([landmarks[336].x * image_shape[1],\n",
    "                                landmarks[336].y * image_shape[0]], dtype=int)     # Index 336 in the facemesh landmarks belongs to the right eyebrow\n",
    "            return left_eyebrow_2d, right_eyebrow_2d\n",
    "        return None, None\n",
    "    \n",
    "    def ears(self, pose_landmarks, image_shape):\n",
    "        \"\"\" Returns 2D coordinates of left and right ears based on the pose landmarks estimated by mediapipe\"\"\"\n",
    "        if pose_landmarks:\n",
    "            landmarks = pose_landmarks.landmark\n",
    "            left_ear_2d = np.array([landmarks[mp.solutions.pose.PoseLandmark.LEFT_EAR].x * image_shape[1],\n",
    "                                landmarks[mp.solutions.pose.PoseLandmark.LEFT_EAR].y * image_shape[0]], dtype=int)\n",
    "            right_ear_2d = np.array([landmarks[mp.solutions.pose.PoseLandmark.RIGHT_EAR].x * image_shape[1],\n",
    "                                landmarks[mp.solutions.pose.PoseLandmark.RIGHT_EAR].y * image_shape[0]], dtype=int)\n",
    "            return left_ear_2d, right_ear_2d\n",
    "        return None, None\n",
    "    \n",
    "    def nose(self, pose_landmarks, image_shape):\n",
    "        \"\"\" Returns 2D coordinates of the nose based on the pose landmarks estimated by mediapipe\"\"\"\n",
    "        if pose_landmarks:\n",
    "            landmarks = pose_landmarks.landmark\n",
    "            nose_2d = np.array([landmarks[mp.solutions.pose.PoseLandmark.NOSE].x * image_shape[1],\n",
    "                                landmarks[mp.solutions.pose.PoseLandmark.NOSE].y * image_shape[0]], dtype=int)\n",
    "            return nose_2d\n",
    "        return None\n",
    "    \n",
    "    def lips(self, facemesh_landmarks, image_shape):\n",
    "        \"\"\" Returns 2D coordinates of upper and lower lips base of the facemesh landmarks estimated by mediapipe\"\"\"\n",
    "        if facemesh_landmarks:\n",
    "            landmarks = facemesh_landmarks.landmark\n",
    "            upper_lip_2d = np.array([landmarks[0].x * image_shape[1],\n",
    "                                landmarks[0].y * image_shape[0]], dtype=int)      # Index 0 in the facemesh landmarks belongs to the upper lip\n",
    "            lower_lip_2d = np.array([landmarks[17].x * image_shape[1],\n",
    "                                landmarks[17].y * image_shape[0]], dtype=int)     # Index 17 in the facemesh landmarks belongs to the lower lip\n",
    "            return upper_lip_2d, lower_lip_2d\n",
    "        return None, None\n",
    "    \n",
    "    def detect_face_gesture(self, frame):\n",
    "        \"\"\"\n",
    "        Detects the face gesture based on the pose and facemesh landmarks provided by Mediapipe.\n",
    "\n",
    "        Returns:\n",
    "            A dictionary containing:\n",
    "            - 'head_detected' : boolean\n",
    "            - 'face_direction': The direction of the head ('left', 'right', 'center', or None).\n",
    "            - 'mouth_open': if True, mouth is open.\n",
    "            An Image with the drawings of the landmarks.\n",
    "        \"\"\"\n",
    "        face_gesture = {'face_detected': False,\n",
    "                        'face_direction': None, \n",
    "                        'mouth_open': None,\n",
    "                        'eye_brows_up': None,}\n",
    "        \n",
    "        # Recolor the frame from GBR to RGB\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        # Make Detections\n",
    "        results = self.holistic.process(frame)\n",
    "        # Recolor image back to BGR for rendering\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        # (image height, image width) of the image in pixels\n",
    "        image_shape = (frame.shape[0], frame.shape[1])\n",
    "        \n",
    "        if not results.pose_landmarks:\n",
    "            return face_gesture, frame\n",
    "        \n",
    "        # drawing the landmarks on the image\n",
    "        if self.draw_pose_landmarks:\n",
    "            self.mp_drawing.draw_landmarks(frame, results.pose_landmarks, self.mp_holistic.POSE_CONNECTIONS)\n",
    "        if self.draw_fasemesh_landmarks:\n",
    "            self.mp_drawing.draw_landmarks(frame, results.face_landmarks, self.mp_holistic.FACEMESH_TESSELATION)\n",
    "        \n",
    "        # 2D coordinates of the left and right ears in pixels: (px, py)\n",
    "        left_ear_2d, right_ear_2d = self.ears(results.pose_landmarks, image_shape)\n",
    "        # 2D coordinates of the nose in pixels: (px, py)\n",
    "        nose_2d = self.nose(results.pose_landmarks, image_shape)\n",
    "        # 2D coordinates of the upper and lower lips in pixels: (px, py)\n",
    "        upper_lip_2d, lower_lip_2d = self.lips(results.face_landmarks, image_shape)\n",
    "        # 2D coordinates of the left and right eyebrows in pixels: (px, py)\n",
    "        left_eyebrow_2d, right_eyebrow_2d = self.eye_brows(results.face_landmarks, image_shape)\n",
    "        # 2D coordinates of the left and right eyes in pixels: (px, py)\n",
    "        left_eye_2d, right_eye_2d = self.eye(results.face_landmarks, image_shape)\n",
    "\n",
    "        # detecting the head direction\n",
    "        if left_ear_2d is not None and right_ear_2d is not None and nose_2d is not None: \n",
    "            face_gesture['face_detected'] = True\n",
    "            # when the face is turned to left, from camera perspective (x-y plane), left ear is closer to the nose\n",
    "            if abs(left_ear_2d[0] - nose_2d[0]) / abs(right_ear_2d[0] - nose_2d[0]) < 1 - self.head_dir_fact:\n",
    "                face_gesture['face_direction'] = \"left\"\n",
    "            # when the face is turned to write, from camera perspective (x-y plane), right ear is closer to the nose\n",
    "            elif abs(left_ear_2d[0] - nose_2d[0]) / abs(right_ear_2d[0] - nose_2d[0]) > 1 + self.head_dir_fact:\n",
    "                face_gesture['face_direction'] = \"right\"\n",
    "            # when the face is looking forward, left and right ears are in a same distance from the noce from the camera perspective\n",
    "            else:\n",
    "                face_gesture['face_direction'] = \"center\"   \n",
    "        else: \n",
    "            face_gesture['face_detected'] = False\n",
    "            face_gesture['face_direction'] = None\n",
    "\n",
    "        # detecting the lips' position\n",
    "        if upper_lip_2d is not None and lower_lip_2d is not None:\n",
    "            if lower_lip_2d[1] - upper_lip_2d[1] > 30 * self.lips_pos_fact:\n",
    "                face_gesture['mouth_open'] = True\n",
    "            else:\n",
    "                face_gesture['mouth_open'] = False\n",
    "        else:\n",
    "            face_gesture['mouth_open'] = None\n",
    "\n",
    "        # detecting the eyebrows up \n",
    "        if left_eyebrow_2d is not None and right_eyebrow_2d is not None:\n",
    "            if abs(left_eyebrow_2d[1] - left_eye_2d[1]) > 25  or abs(right_eyebrow_2d[1] - right_eye_2d[1]) > 25:\n",
    "                face_gesture['eye_brows_up'] = True\n",
    "            else:\n",
    "                face_gesture['eye_brows_up'] = False\n",
    "        else:\n",
    "            face_gesture['eye_brows_up'] = None\n",
    "        return face_gesture, frame\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The belowing cell, just takes the frames from the camera, detects the fase gesture and shows the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[0;32m      9\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m---> 11\u001b[0m     face_gesture, image \u001b[38;5;241m=\u001b[39m \u001b[43mface_gesture_detector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_face_gesture\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m face_gesture[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mface_detected\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     14\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mputText(image, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mface direction: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mface_gesture[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mface_direction\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m40\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m0.5\u001b[39m, (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[29], line 85\u001b[0m, in \u001b[0;36mFaseGestureDetector.detect_face_gesture\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m     83\u001b[0m frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Make Detections\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mholistic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Recolor image back to BGR for rendering\u001b[39;00m\n\u001b[0;32m     87\u001b[0m frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2BGR)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\carla-cp39\\lib\\site-packages\\mediapipe\\python\\solutions\\holistic.py:160\u001b[0m, in \u001b[0;36mHolistic.process\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[0;32m    137\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the pose landmarks, left and right hand landmarks, and face landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \n\u001b[0;32m    139\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m         \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m landmark \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\carla-cp39\\lib\\site-packages\\mediapipe\\python\\solution_base.py:340\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    334\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[0;32m    336\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[0;32m    337\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[0;32m    338\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize the face gesture detector\n",
    "face_gesture_detector = FaseGestureDetector()\n",
    "face_gesture_detector.draw_pose_landmarks = True\n",
    "face_gesture_detector.draw_fasemesh_landmarks = False\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "    \n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "        \n",
    "    face_gesture, image = face_gesture_detector.detect_face_gesture(frame)\n",
    "\n",
    "    if face_gesture['face_detected']:\n",
    "        cv2.putText(image, f\"face direction: {face_gesture['face_direction']}\", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)\n",
    "    if face_gesture['mouth_open'] is not None and face_gesture['face_detected']:\n",
    "        cv2.putText(image, \"mouth position: open\" if face_gesture['mouth_open'] else \"mouth position: close\", (20, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)\n",
    "    if face_gesture['eye_brows_up'] is not None and face_gesture['face_detected']:\n",
    "        cv2.putText(image, \"eye_brows position: up\" if face_gesture['eye_brows_up'] else \"eye_brows position: down\", (20, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)\n",
    "    cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "###     Global Functions    ###\n",
    "###############################    \n",
    "\n",
    "def get_actor_display_name(actor, truncate=250):\n",
    "    name = ' '.join(actor.type_id.replace('_', '.').title().split('.')[1:])\n",
    "    return (name[:truncate - 1] + u'\\u2026') if len(name) > truncate else name\n",
    "\n",
    "def get_actor_blueprints(world, filter, generation):\n",
    "    bps = world.get_blueprint_library().filter(filter)\n",
    "\n",
    "    if generation.lower() == \"all\":\n",
    "        return bps\n",
    "\n",
    "    # If the filter returns only one bp, we assume that this one needed\n",
    "    # and therefore, we ignore the generation\n",
    "    if len(bps) == 1:\n",
    "        return bps\n",
    "\n",
    "    try:\n",
    "        int_generation = int(generation)\n",
    "        # Check if generation is in available generations\n",
    "        if int_generation in [1, 2, 3]:\n",
    "            bps = [x for x in bps if int(x.get_attribute('generation')) == int_generation]\n",
    "            return bps\n",
    "        else:\n",
    "            print(\"   Warning! Actor Generation is not valid. No actor will be spawned.\")\n",
    "            return []\n",
    "    except:\n",
    "        print(\"   Warning! Actor Generation is not valid. No actor will be spawned.\")\n",
    "        return []\n",
    "\n",
    "###############################\n",
    "###     Camera Manager      ###\n",
    "###############################   \n",
    "\n",
    "class CameraManager(object):\n",
    "    def __init__(self, parent_actor, hud, gamma_correction):\n",
    "        self.sensor = None\n",
    "        self.surface = None\n",
    "        self._parent = parent_actor\n",
    "        self.hud = hud\n",
    "        self.recording = False\n",
    "        bound_x = 0.5 + self._parent.bounding_box.extent.x\n",
    "        bound_y = 0.5 + self._parent.bounding_box.extent.y\n",
    "        bound_z = 0.5 + self._parent.bounding_box.extent.z\n",
    "        Attachment = carla.AttachmentType\n",
    "\n",
    "        \n",
    "        self._camera_transforms = [\n",
    "            (carla.Transform(carla.Location(x=-2.0*bound_x, y=+0.0*bound_y, z=2.0*bound_z), carla.Rotation(pitch=8.0)), Attachment.SpringArmGhost),\n",
    "            (carla.Transform(carla.Location(x=+0.8*bound_x, y=+0.0*bound_y, z=1.3*bound_z)), Attachment.Rigid),\n",
    "            (carla.Transform(carla.Location(x=+1.9*bound_x, y=+1.0*bound_y, z=1.2*bound_z)), Attachment.SpringArmGhost),\n",
    "            (carla.Transform(carla.Location(x=-2.8*bound_x, y=+0.0*bound_y, z=4.6*bound_z), carla.Rotation(pitch=6.0)), Attachment.SpringArmGhost),\n",
    "            (carla.Transform(carla.Location(x=-1.0, y=-1.0*bound_y, z=0.4*bound_z)), Attachment.Rigid)]\n",
    "        \n",
    "\n",
    "        self.transform_index = 1\n",
    "        self.sensors = [\n",
    "            ['sensor.camera.rgb', cc.Raw, 'Camera RGB', {}]\n",
    "        ]\n",
    "\n",
    "        world = self._parent.get_world()\n",
    "        bp_library = world.get_blueprint_library()\n",
    "        for item in self.sensors:\n",
    "            bp = bp_library.find(item[0])\n",
    "            if item[0].startswith('sensor.camera'):\n",
    "                bp.set_attribute('image_size_x', str(hud.dim[0]))\n",
    "                bp.set_attribute('image_size_y', str(hud.dim[1]))\n",
    "                if bp.has_attribute('gamma'):\n",
    "                    bp.set_attribute('gamma', str(gamma_correction))\n",
    "                for attr_name, attr_value in item[3].items():\n",
    "                    bp.set_attribute(attr_name, attr_value)\n",
    "\n",
    "                for attr_name, attr_value in item[3].items():\n",
    "                    bp.set_attribute(attr_name, attr_value)\n",
    "                    if attr_name == 'range':\n",
    "                        self.lidar_range = float(attr_value)\n",
    "\n",
    "            item.append(bp)\n",
    "        self.index = None\n",
    "\n",
    "    def toggle_camera(self):\n",
    "        self.transform_index = (self.transform_index + 1) % len(self._camera_transforms)\n",
    "        self.set_sensor(self.index, notify=False, force_respawn=True)\n",
    "\n",
    "    def set_sensor(self, index, notify=True, force_respawn=False):\n",
    "        index = index % len(self.sensors)\n",
    "        needs_respawn = True if self.index is None else \\\n",
    "            (force_respawn or (self.sensors[index][2] != self.sensors[self.index][2]))\n",
    "        if needs_respawn:\n",
    "            if self.sensor is not None:\n",
    "                self.sensor.destroy()\n",
    "                self.surface = None\n",
    "            self.sensor = self._parent.get_world().spawn_actor(\n",
    "                self.sensors[index][-1],\n",
    "                self._camera_transforms[self.transform_index][0],\n",
    "                attach_to=self._parent,\n",
    "                attachment_type=self._camera_transforms[self.transform_index][1])\n",
    "            # We need to pass the lambda a weak reference to self to avoid\n",
    "            # circular reference.\n",
    "            weak_self = weakref.ref(self)\n",
    "            self.sensor.listen(lambda image: CameraManager._parse_image(weak_self, image))\n",
    "        if notify:\n",
    "            self.hud.notification(self.sensors[index][2])\n",
    "        self.index = index\n",
    "\n",
    "    def next_sensor(self):\n",
    "        self.set_sensor(self.index + 1)\n",
    "\n",
    "    def toggle_recording(self):\n",
    "        self.recording = not self.recording\n",
    "        self.hud.notification('Recording %s' % ('On' if self.recording else 'Off'))\n",
    "\n",
    "    def render(self, display):\n",
    "        if self.surface is not None:\n",
    "            display.blit(self.surface, (0, 0))\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_image(weak_self, image):\n",
    "        self = weak_self()\n",
    "        if not self:\n",
    "            return\n",
    "        \n",
    "        image.convert(self.sensors[self.index][1])\n",
    "        array = np.frombuffer(image.raw_data, dtype=np.dtype(\"uint8\"))\n",
    "        array = np.reshape(array, (image.height, image.width, 4))\n",
    "        array = array[:, :, :3]\n",
    "        array = array[:, :, ::-1]\n",
    "        self.surface = pygame.surfarray.make_surface(array.swapaxes(0, 1))\n",
    "\n",
    "        if self.recording:\n",
    "            image.save_to_disk('_out/%08d' % image.frame)\n",
    "\n",
    "###############################\n",
    "###          HUD            ###\n",
    "############################### \n",
    "\n",
    "class FadingText(object):\n",
    "    def __init__(self, font, dim, pos):\n",
    "        self.font = font\n",
    "        self.dim = dim\n",
    "        self.pos = pos\n",
    "        self.seconds_left = 0\n",
    "        self.surface = pygame.Surface(self.dim)\n",
    "\n",
    "    def set_text(self, text, color=(255, 255, 255), seconds=2.0):\n",
    "        text_texture = self.font.render(text, True, color)\n",
    "        self.surface = pygame.Surface(self.dim)\n",
    "        self.seconds_left = seconds\n",
    "        self.surface.fill((0, 0, 0, 0))\n",
    "        self.surface.blit(text_texture, (10, 11))\n",
    "\n",
    "    def tick(self, _, clock):\n",
    "        delta_seconds = 1e-3 * clock.get_time()\n",
    "        self.seconds_left = max(0.0, self.seconds_left - delta_seconds)\n",
    "        self.surface.set_alpha(500.0 * self.seconds_left)\n",
    "\n",
    "    def render(self, display):\n",
    "        display.blit(self.surface, self.pos)\n",
    "\n",
    "class HelpText(object):\n",
    "    \"\"\"Helper class to handle text output using pygame\"\"\"\n",
    "    def __init__(self, font, width, height):\n",
    "        lines = __doc__.split('\\n')\n",
    "        self.font = font\n",
    "        self.line_space = 18\n",
    "        self.dim = (780, len(lines) * self.line_space + 12)\n",
    "        self.pos = (0.5 * width - 0.5 * self.dim[0], 0.5 * height - 0.5 * self.dim[1])\n",
    "        self.seconds_left = 0\n",
    "        self.surface = pygame.Surface(self.dim)\n",
    "        self.surface.fill((0, 0, 0, 0))\n",
    "        for n, line in enumerate(lines):\n",
    "            text_texture = self.font.render(line, True, (255, 255, 255))\n",
    "            self.surface.blit(text_texture, (22, n * self.line_space))\n",
    "            self._render = False\n",
    "        self.surface.set_alpha(220)\n",
    "\n",
    "    def toggle(self):\n",
    "        self._render = not self._render\n",
    "\n",
    "    def render(self, display):\n",
    "        if self._render:\n",
    "            display.blit(self.surface, self.pos)\n",
    "\n",
    "class HUD(object):\n",
    "    def __init__(self, width, height):\n",
    "        self.dim = (width, height)\n",
    "        font = pygame.font.Font(pygame.font.get_default_font(), 20)\n",
    "        font_name = 'courier' if os.name == 'nt' else 'mono'\n",
    "        fonts = [x for x in pygame.font.get_fonts() if font_name in x]\n",
    "        default_font = 'ubuntumono'\n",
    "        mono = default_font if default_font in fonts else fonts[0]\n",
    "        mono = pygame.font.match_font(mono)\n",
    "        self._font_mono = pygame.font.Font(mono, 12 if os.name == 'nt' else 14)\n",
    "        self._notifications = FadingText(font, (width, 40), (0, height - 40))\n",
    "        self.help = HelpText(pygame.font.Font(mono, 16), width, height)\n",
    "        self.server_fps = 0\n",
    "        self.frame = 0\n",
    "        self.simulation_time = 0\n",
    "        self._show_info = True\n",
    "        self._info_text = []\n",
    "        self._server_clock = pygame.time.Clock()\n",
    "\n",
    "        self._ackermann_control = carla.VehicleAckermannControl()\n",
    "\n",
    "    def on_world_tick(self, timestamp):\n",
    "        self._server_clock.tick()\n",
    "        self.server_fps = self._server_clock.get_fps()\n",
    "        self.frame = timestamp.frame\n",
    "        self.simulation_time = timestamp.elapsed_seconds\n",
    "\n",
    "    def tick(self, world, clock):\n",
    "        self._notifications.tick(world, clock)\n",
    "        if not self._show_info:\n",
    "            return\n",
    "        t = world.player.get_transform()\n",
    "        v = world.player.get_velocity()\n",
    "        c = world.player.get_control()\n",
    "\n",
    "        self._info_text = [\n",
    "            'Server:  % 16.0f FPS' % self.server_fps,\n",
    "            'Client:  % 16.0f FPS' % clock.get_fps(),\n",
    "            '',\n",
    "            'Vehicle: % 20s' % get_actor_display_name(world.player, truncate=20),\n",
    "            'Map:     % 20s' % world.map.name.split('/')[-1],\n",
    "            'Simulation time: % 12s' % datetime.timedelta(seconds=int(self.simulation_time)),\n",
    "            '',\n",
    "            'Speed:   % 15.0f km/h' % (3.6 * math.sqrt(v.x**2 + v.y**2 + v.z**2)),\n",
    "            'Location:% 20s' % ('(% 5.1f, % 5.1f)' % (t.location.x, t.location.y)),\n",
    "            'Height:  % 18.0f m' % t.location.z,\n",
    "            '']\n",
    "        \n",
    "        self._info_text += [\n",
    "            ('Throttle:', c.throttle, 0.0, 1.0),\n",
    "            ('Steer:', c.steer, -1.0, 1.0),\n",
    "            ('Brake:', c.brake, 0.0, 1.0),\n",
    "            ('Reverse:', c.reverse),\n",
    "            ('Manual:', c.manual_gear_shift),\n",
    "            'Gear:        %s' % {-1: 'R', 0: 'N'}.get(c.gear, c.gear)]\n",
    "\n",
    "    def update_ackermann_control(self, ackermann_control):\n",
    "        self._ackermann_control = ackermann_control\n",
    "\n",
    "    def toggle_info(self):\n",
    "        self._show_info = not self._show_info\n",
    "\n",
    "    def notification(self, text, seconds=2.0):\n",
    "        self._notifications.set_text(text, seconds=seconds)\n",
    "\n",
    "    def error(self, text):\n",
    "        self._notifications.set_text('Error: %s' % text, (255, 0, 0))\n",
    "\n",
    "    def render(self, display):\n",
    "        if self._show_info:\n",
    "            info_surface = pygame.Surface((220, self.dim[1]))\n",
    "            info_surface.set_alpha(100)\n",
    "            display.blit(info_surface, (0, 0))\n",
    "            v_offset = 4\n",
    "            bar_h_offset = 100\n",
    "            bar_width = 106\n",
    "            for item in self._info_text:\n",
    "                if v_offset + 18 > self.dim[1]:\n",
    "                    break\n",
    "                if isinstance(item, list):\n",
    "                    if len(item) > 1:\n",
    "                        points = [(x + 8, v_offset + 8 + (1.0 - y) * 30) for x, y in enumerate(item)]\n",
    "                        pygame.draw.lines(display, (255, 136, 0), False, points, 2)\n",
    "                    item = None\n",
    "                    v_offset += 18\n",
    "                elif isinstance(item, tuple):\n",
    "                    if isinstance(item[1], bool):\n",
    "                        rect = pygame.Rect((bar_h_offset, v_offset + 8), (6, 6))\n",
    "                        pygame.draw.rect(display, (255, 255, 255), rect, 0 if item[1] else 1)\n",
    "                    else:\n",
    "                        rect_border = pygame.Rect((bar_h_offset, v_offset + 8), (bar_width, 6))\n",
    "                        pygame.draw.rect(display, (255, 255, 255), rect_border, 1)\n",
    "                        f = (item[1] - item[2]) / (item[3] - item[2])\n",
    "                        if item[2] < 0.0:\n",
    "                            rect = pygame.Rect((bar_h_offset + f * (bar_width - 6), v_offset + 8), (6, 6))\n",
    "                        else:\n",
    "                            rect = pygame.Rect((bar_h_offset, v_offset + 8), (f * bar_width, 6))\n",
    "                        pygame.draw.rect(display, (255, 255, 255), rect)\n",
    "                    item = item[0]\n",
    "                if item:  # At this point has to be a str.\n",
    "                    surface = self._font_mono.render(item, True, (255, 255, 255))\n",
    "                    display.blit(surface, (8, v_offset))\n",
    "                v_offset += 18\n",
    "        self._notifications.render(display)\n",
    "        self.help.render(display)\n",
    "\n",
    "###############################\n",
    "###         World           ###\n",
    "############################### \n",
    "\n",
    "class World(object):\n",
    "    def __init__(self, carla_world, hud, args):\n",
    "        self.world = carla_world\n",
    "        self.sync = args['sync']\n",
    "        self.render_camera = args['rend_cam']\n",
    "        try:\n",
    "            self.map = self.world.get_map()\n",
    "        except RuntimeError as error:\n",
    "            print('RuntimeError: {}'.format(error))\n",
    "            print('  The server could not send the OpenDRIVE (.xodr) file:')\n",
    "            print('  Make sure it exists, has the same name of your town, and is correct.')\n",
    "            sys.exit(1)\n",
    "        self.hud = hud\n",
    "        self.player = None\n",
    "        self.camera_manager = None\n",
    "        self._actor_filter = args['filter']\n",
    "        self._actor_generation = args['generation']\n",
    "        self._gamma = args['gamma']\n",
    "        self.restart()\n",
    "        self.world.on_tick(hud.on_world_tick)\n",
    "\n",
    "    def restart(self):\n",
    "        self.player_max_speed = 1.589\n",
    "        self.player_max_speed_fast = 3.713\n",
    "        # Keep same camera config if the camera manager exists.\n",
    "        cam_index = self.camera_manager.index if self.camera_manager is not None else 0\n",
    "        cam_pos_index = self.camera_manager.transform_index if self.camera_manager is not None else 0\n",
    "        # Get a random blueprint.\n",
    "        blueprint_list = get_actor_blueprints(self.world, self._actor_filter, self._actor_generation)\n",
    "        if not blueprint_list:\n",
    "            raise ValueError(\"Couldn't find any blueprints with the specified filters\")\n",
    "        blueprint = random.choice(blueprint_list)\n",
    "        if blueprint.has_attribute('terramechanics'):\n",
    "            blueprint.set_attribute('terramechanics', 'true')\n",
    "        if blueprint.has_attribute('color'):\n",
    "            color = random.choice(blueprint.get_attribute('color').recommended_values)\n",
    "            blueprint.set_attribute('color', color)\n",
    "        if blueprint.has_attribute('driver_id'):\n",
    "            driver_id = random.choice(blueprint.get_attribute('driver_id').recommended_values)\n",
    "            blueprint.set_attribute('driver_id', driver_id)\n",
    "        if blueprint.has_attribute('is_invincible'):\n",
    "            blueprint.set_attribute('is_invincible', 'true')\n",
    "        # set the max speed\n",
    "        if blueprint.has_attribute('speed'):\n",
    "            self.player_max_speed = float(blueprint.get_attribute('speed').recommended_values[1])\n",
    "            self.player_max_speed_fast = float(blueprint.get_attribute('speed').recommended_values[2])\n",
    "\n",
    "        # Spawn the player.\n",
    "        if self.player is not None:\n",
    "            spawn_point = self.player.get_transform()\n",
    "            spawn_point.location.z += 2.0\n",
    "            spawn_point.rotation.roll = 0.0\n",
    "            spawn_point.rotation.pitch = 0.0\n",
    "            self.destroy()\n",
    "            self.player = self.world.try_spawn_actor(blueprint, spawn_point)\n",
    "            self.modify_vehicle_physics(self.player)\n",
    "        while self.player is None:\n",
    "            if not self.map.get_spawn_points():\n",
    "                print('There are no spawn points available in your map/town.')\n",
    "                print('Please add some Vehicle Spawn Point to your UE4 scene.')\n",
    "                sys.exit(1)\n",
    "            spawn_points = self.map.get_spawn_points()\n",
    "            spawn_point = random.choice(spawn_points) if spawn_points else carla.Transform()\n",
    "            self.player = self.world.try_spawn_actor(blueprint, spawn_point)\n",
    "            self.show_vehicle_telemetry = False\n",
    "            self.modify_vehicle_physics(self.player)\n",
    "        # set sensors\n",
    "        self.camera_manager = CameraManager(self.player, self.hud, self._gamma)\n",
    "        self.camera_manager.transform_index = cam_pos_index\n",
    "        self.camera_manager.set_sensor(cam_index, notify=False)\n",
    "        actor_type = get_actor_display_name(self.player)\n",
    "        self.hud.notification(actor_type)\n",
    "\n",
    "        if self.sync:\n",
    "            self.world.tick()\n",
    "        else:\n",
    "            self.world.wait_for_tick()\n",
    "\n",
    "    def modify_vehicle_physics(self, actor):\n",
    "        #If actor is not a vehicle, we cannot use the physics control\n",
    "        try:\n",
    "            physics_control = actor.get_physics_control()\n",
    "            physics_control.use_sweep_wheel_collision = True\n",
    "            actor.apply_physics_control(physics_control)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    def tick(self, clock):\n",
    "        self.hud.tick(self, clock)\n",
    "\n",
    "    def render(self, display):\n",
    "        if self.render_camera:\n",
    "            self.camera_manager.render(display)\n",
    "        self.hud.render(display)\n",
    "\n",
    "    def destroy_sensors(self):\n",
    "        self.camera_manager.sensor.destroy()\n",
    "        self.camera_manager.sensor = None\n",
    "        self.camera_manager.index = None\n",
    "\n",
    "    def destroy(self):\n",
    "        sensors = [self.camera_manager.sensor]\n",
    "        for sensor in sensors:\n",
    "            if sensor is not None:\n",
    "                sensor.stop()\n",
    "                sensor.destroy()\n",
    "        if self.player is not None:\n",
    "            self.player.destroy()\n",
    "\n",
    "###############################\n",
    "###   Face Controller   ###\n",
    "############################### \n",
    "\n",
    "class FaceControl(object):\n",
    "    \"\"\"Class that handles keyboard input.\"\"\"\n",
    "    def __init__(self, world):\n",
    "        self._ackermann_enabled = False\n",
    "        self._ackermann_reverse = 1\n",
    "        # face control flag\n",
    "        self._face_control_enabled = False\n",
    "\n",
    "        self._control = carla.VehicleControl()\n",
    "        self._ackermann_control = carla.VehicleAckermannControl()\n",
    "        self._lights = carla.VehicleLightState.NONE\n",
    "\n",
    "        world.player.set_light_state(self._lights)\n",
    "        \n",
    "        self._steer_cache = 0.0\n",
    "        world.hud.notification(\"Press 'H' or '?' for help.\", seconds=4.0)\n",
    "\n",
    "        # Initialize the face gesture detector\n",
    "        self.face_gesture_detector = FaseGestureDetector()\n",
    "        self.face_gesture_detector.draw_pose_landmarks = True\n",
    "        self.face_gesture_detector.draw_fasemesh_landmarks = False\n",
    "\n",
    "    def parse_events(self, frame, world, clock):\n",
    "        # Detecting the face gesture with mediapipe \n",
    "        face_gesture, image = self.face_gesture_detector.detect_face_gesture(frame)\n",
    "        cv2.putText(image, f\"head direction: {face_gesture['face_direction']}\", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)\n",
    "        cv2.putText(image, f\"lips position: {face_gesture['mouth_open']}\", (20, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)\n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        current_lights = self._lights\n",
    "\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                return True\n",
    "            elif event.type == pygame.KEYUP:\n",
    "                # quit\n",
    "                if self._is_quit_shortcut(event.key):\n",
    "                    return True\n",
    "                \n",
    "                elif event.key == K_q:\n",
    "                    if not self._ackermann_enabled:\n",
    "                        self._control.gear = 1 if self._control.reverse else -1\n",
    "                    else:\n",
    "                        self._ackermann_reverse *= -1\n",
    "                        # Reset ackermann control\n",
    "                        self._ackermann_control = carla.VehicleAckermannControl()\n",
    "                \n",
    "                # Switch the manuel gear shift\n",
    "                elif event.key == K_m:\n",
    "                    self._control.manual_gear_shift = not self._control.manual_gear_shift\n",
    "                    self._control.gear = world.player.get_control().gear\n",
    "                    world.hud.notification('%s Transmission' % ('Manual' if self._control.manual_gear_shift else 'Automatic'))\n",
    "                # shift down\n",
    "                elif self._control.manual_gear_shift and event.key == K_COMMA:\n",
    "                    self._control.gear = max(-1, self._control.gear - 1)\n",
    "                # shift up\n",
    "                elif self._control.manual_gear_shift and event.key == K_PERIOD:\n",
    "                    self._control.gear = self._control.gear + 1\n",
    "\n",
    "                # switch the face control enable\n",
    "                elif event.key == K_f:\n",
    "                    self._face_control_enabled = not self._face_control_enabled\n",
    "        \n",
    "        # if face_drive is enabled, use face control, otherwise use manuel control \n",
    "        if not self._face_control_enabled:\n",
    "            self._parse_vehicle_keys(pygame.key.get_pressed(), clock.get_time())\n",
    "        else:\n",
    "            self._parse_face_gesture(face_gesture, clock.get_time())\n",
    "\n",
    "        self._control.reverse = self._control.gear < 0\n",
    "        # Set automatic control-related vehicle lights\n",
    "        if self._control.brake:\n",
    "            current_lights |= carla.VehicleLightState.Brake\n",
    "        else: # Remove the Brake flag\n",
    "            current_lights &= ~carla.VehicleLightState.Brake\n",
    "        if self._control.reverse:\n",
    "            current_lights |= carla.VehicleLightState.Reverse\n",
    "        else: # Remove the Reverse flag\n",
    "            current_lights &= ~carla.VehicleLightState.Reverse\n",
    "        if current_lights != self._lights: # Change the light state only if necessary\n",
    "            self._lights = current_lights\n",
    "            world.player.set_light_state(carla.VehicleLightState(self._lights))\n",
    "        # Apply control\n",
    "        if not self._ackermann_enabled:\n",
    "            world.player.apply_control(self._control)\n",
    "        else:\n",
    "            world.player.apply_ackermann_control(self._ackermann_control)\n",
    "            # Update control to the last one applied by the ackermann controller.\n",
    "            self._control = world.player.get_control()\n",
    "            # Update hud with the newest ackermann control\n",
    "            world.hud.update_ackermann_control(self._ackermann_control)\n",
    "\n",
    "    def _parse_face_gesture(self, face_gesture, milliseconds): \n",
    "        # if any face is detected, accelerate\n",
    "        if face_gesture['mouth_open'] and not face_gesture['eye_brows_up']:\n",
    "            if not self._ackermann_enabled:\n",
    "                self._control.throttle = min(self._control.throttle + 0.1, 1.00)\n",
    "            else:\n",
    "                self._ackermann_control.speed += round(milliseconds * 0.005, 2) * self._ackermann_reverse\n",
    "        else:\n",
    "            if not self._ackermann_enabled:\n",
    "                self._control.throttle = 0.0\n",
    "        # if mouth is open, break\n",
    "        if face_gesture['eye_brows_up']:\n",
    "            if not self._ackermann_enabled:\n",
    "                self._control.brake = min(self._control.brake + 0.2, 1)\n",
    "            else:\n",
    "                self._ackermann_control.speed -= min(abs(self._ackermann_control.speed), round(milliseconds * 0.005, 2)) * self._ackermann_reverse\n",
    "                self._ackermann_control.speed = max(0, abs(self._ackermann_control.speed)) * self._ackermann_reverse\n",
    "        else:\n",
    "            if not self._ackermann_enabled:\n",
    "                self._control.brake = 0\n",
    "\n",
    "        steer_increment = 5e-4 * milliseconds\n",
    "        # if face is looking to the left, steer to the left\n",
    "        if face_gesture['face_detected'] and face_gesture['face_direction'] == 'left':\n",
    "            if self._steer_cache > 0:\n",
    "                self._steer_cache = 0\n",
    "            else:\n",
    "                self._steer_cache -= steer_increment\n",
    "        # if face is looking to the right, steer to the right\n",
    "        elif face_gesture['face_detected'] and face_gesture['face_direction'] == 'right':\n",
    "            if self._steer_cache < 0:\n",
    "                self._steer_cache = 0\n",
    "            else:\n",
    "                self._steer_cache += steer_increment\n",
    "        else:\n",
    "            self._steer_cache = 0.0\n",
    "        self._steer_cache = min(0.7, max(-0.7, self._steer_cache))\n",
    "        if not self._ackermann_enabled:\n",
    "            self._control.steer = round(self._steer_cache, 1)\n",
    "        else:\n",
    "            self._ackermann_control.steer = round(self._steer_cache, 1)\n",
    "\n",
    "    def _parse_vehicle_keys(self, keys, milliseconds):\n",
    "        if keys[K_UP] or keys[K_w]:\n",
    "            if not self._ackermann_enabled:\n",
    "                self._control.throttle = min(self._control.throttle + 0.1, 1.00)\n",
    "            else:\n",
    "                self._ackermann_control.speed += round(milliseconds * 0.005, 2) * self._ackermann_reverse\n",
    "        else:\n",
    "            if not self._ackermann_enabled:\n",
    "                self._control.throttle = 0.0\n",
    "\n",
    "        if keys[K_DOWN] or keys[K_s]:\n",
    "            if not self._ackermann_enabled:\n",
    "                self._control.brake = min(self._control.brake + 0.2, 1)\n",
    "            else:\n",
    "                self._ackermann_control.speed -= min(abs(self._ackermann_control.speed), round(milliseconds * 0.005, 2)) * self._ackermann_reverse\n",
    "                self._ackermann_control.speed = max(0, abs(self._ackermann_control.speed)) * self._ackermann_reverse\n",
    "        else:\n",
    "            if not self._ackermann_enabled:\n",
    "                self._control.brake = 0\n",
    "\n",
    "        steer_increment = 5e-4 * milliseconds\n",
    "        if keys[K_LEFT] or keys[K_a]:\n",
    "            if self._steer_cache > 0:\n",
    "                self._steer_cache = 0\n",
    "            else:\n",
    "                self._steer_cache -= steer_increment\n",
    "        elif keys[K_RIGHT] or keys[K_d]:\n",
    "            if self._steer_cache < 0:\n",
    "                self._steer_cache = 0\n",
    "            else:\n",
    "                self._steer_cache += steer_increment\n",
    "        else:\n",
    "            self._steer_cache = 0.0\n",
    "        self._steer_cache = min(0.7, max(-0.7, self._steer_cache))\n",
    "        if not self._ackermann_enabled:\n",
    "            self._control.steer = round(self._steer_cache, 1)\n",
    "            self._control.hand_brake = keys[K_SPACE]\n",
    "        else:\n",
    "            self._ackermann_control.steer = round(self._steer_cache, 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def _is_quit_shortcut(key):\n",
    "        return (key == K_ESCAPE) or (key == K_q and pygame.key.get_mods() & KMOD_CTRL)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use ARROWS or WASD keys for control.\n",
    "\n",
    "    Up           : throttle\n",
    "    Down         : brake\n",
    "    Left/Right   : steer left/right\n",
    "    Q            : toggle reverse\n",
    "    Space        : hand-brake\n",
    "    M            : toggle manual transmission\n",
    "    ,/.          : gear up/down\n",
    "    CTRL + W     : toggle constant velocity mode at 60 km/h\n",
    "\n",
    "    F1           : toggle HUD\n",
    "    H/?          : toggle help\n",
    "    ESC          : quit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "###   Face drive game loop    ###\n",
    "#################################\n",
    "\n",
    "def face_drive_game_loop(args):\n",
    "    pygame.init()\n",
    "    pygame.font.init()\n",
    "    world = None\n",
    "    original_settings = None\n",
    "\n",
    "    try:\n",
    "        client = carla.Client(args['host'], args['port'])\n",
    "        client.set_timeout(2000.0)\n",
    "\n",
    "        sim_world = client.get_world()\n",
    "        \n",
    "        display = pygame.display.set_mode(\n",
    "            (args['width'], args['height']),\n",
    "            pygame.HWSURFACE | pygame.DOUBLEBUF)\n",
    "        display.fill((0,0,0))\n",
    "        pygame.display.flip()\n",
    "\n",
    "        hud = HUD(args['width'], args['height'])\n",
    "        world = World(sim_world, hud, args)\n",
    "\n",
    "        controller = FaceControl(world)\n",
    "        \n",
    "        sim_world.wait_for_tick()\n",
    "\n",
    "        clock = pygame.time.Clock()\n",
    "        \n",
    "        cap = cv2.VideoCapture(0)\n",
    "    \n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            clock.tick_busy_loop(60)\n",
    "\n",
    "            if controller.parse_events(frame, world, clock):\n",
    "                return\n",
    "            \n",
    "            world.tick(clock)\n",
    "            world.render(display)\n",
    "            pygame.display.flip()\n",
    "\n",
    "    finally:\n",
    "        if original_settings:\n",
    "            sim_world.apply_settings(original_settings)\n",
    "\n",
    "        if world is not None:\n",
    "            world.destroy()\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        pygame.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    args = {'debug': False,\n",
    "            'host': '35.199.85.236',\n",
    "            'port': 2000,\n",
    "            'res': '640x360',\n",
    "            'filter': 'vehicle.*',\n",
    "            'generation': '2',\n",
    "            'gamma': 2.2,\n",
    "            'sync': False,\n",
    "            'rend_cam' : True}\n",
    "    \n",
    "    args['width'], args['height'] = [int(x) for x in args['res'].split('x')]\n",
    "\n",
    "    log_level = logging.DEBUG if args['debug'] else logging.INFO\n",
    "    logging.basicConfig(format='%(levelname)s: %(message)s', level=log_level)\n",
    "\n",
    "    logging.info('listening to server %s:%s', args['host'], args['port'])\n",
    "\n",
    "    print(__doc__)\n",
    "\n",
    "    try:\n",
    "        #manuel_game_loop(args)\n",
    "        face_drive_game_loop(args)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print('\\nCancelled by user. Bye!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: listening to server 35.199.85.236:2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "\n",
      "Cancelled by user. Bye!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcap\u001b[49m\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m      2\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cap' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla-cp39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
